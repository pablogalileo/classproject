{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROYECTO FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "digitos = pd.read_csv('train.csv')\n",
    "digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos si hay columnas que tengamos que hacerle algún tipo de imputación\n",
    "cols_con_na = [col for col in digitos.columns if(digitos[col].isnull().mean()>0)]\n",
    "cols_con_na\n",
    "#Observamos que no hay ninguna columna con valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el dataset en variables independientes X y dependientes y\n",
    "X = digitos.drop(columns=['label']).values\n",
    "y = digitos['label'].values\n",
    "\n",
    "# Realizamos el reshape para convertir los valores de la tabla en imagenes\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "#Realizamos el One Hot Encoding a la variable dependiente, son 10 clases ya que va de 0 a 9\n",
    "y = to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Realizamos un vistazo rapido de algunos valores para asegurar que se hayan generado bien las imagenes\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {np.argmax(y[i])}') \n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,shuffle=True, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializamos el modelo\n",
    "modelANN = kr.models.Sequential()\n",
    "\n",
    "modelANN.add(kr.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "\n",
    "#Agregramos la primera capa oculta, una capa densa\n",
    "modelANN.add(kr.layers.Dense(input_dim=784,units=1024,activation='relu'))\n",
    "\n",
    "#Segunda capa oculta\n",
    "modelANN.add(kr.layers.Dense(units=512,activation='relu'))\n",
    "\n",
    "#Tercera capa oculta\n",
    "modelANN.add(kr.layers.Dense(units=256,activation='relu'))\n",
    "\n",
    "#Capa de salida\n",
    "modelANN.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1050/1050 [==============================] - 22s 20ms/step - loss: 1.3953 - accuracy: 0.8882\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.2277 - accuracy: 0.9413\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.1809 - accuracy: 0.9523\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.1496 - accuracy: 0.9594\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.1311 - accuracy: 0.9642\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.1138 - accuracy: 0.9682\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 25s 24ms/step - loss: 0.1042 - accuracy: 0.9711\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.1019 - accuracy: 0.9740\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0934 - accuracy: 0.9768\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0949 - accuracy: 0.9773\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0652 - accuracy: 0.9825\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0745 - accuracy: 0.9814\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0602 - accuracy: 0.9853\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0884 - accuracy: 0.9810\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0635 - accuracy: 0.9856\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0529 - accuracy: 0.9884\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0494 - accuracy: 0.9882\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0689 - accuracy: 0.9854\n",
      "Epoch 19/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0603 - accuracy: 0.9874\n",
      "Epoch 20/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0477 - accuracy: 0.9887\n",
      "Epoch 21/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0501 - accuracy: 0.9892\n",
      "Epoch 22/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0562 - accuracy: 0.9881\n",
      "Epoch 23/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0457 - accuracy: 0.9908\n",
      "Epoch 24/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0602 - accuracy: 0.9894\n",
      "Epoch 25/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0731 - accuracy: 0.9888\n",
      "Epoch 26/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0369 - accuracy: 0.9921\n",
      "Epoch 27/50\n",
      "1050/1050 [==============================] - 22s 20ms/step - loss: 0.0436 - accuracy: 0.9926\n",
      "Epoch 28/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0488 - accuracy: 0.9911\n",
      "Epoch 29/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0545 - accuracy: 0.9908\n",
      "Epoch 30/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0539 - accuracy: 0.9912\n",
      "Epoch 31/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0372 - accuracy: 0.9935\n",
      "Epoch 32/50\n",
      "1050/1050 [==============================] - 22s 21ms/step - loss: 0.0491 - accuracy: 0.9919\n",
      "Epoch 33/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0608 - accuracy: 0.9893\n",
      "Epoch 34/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0491 - accuracy: 0.9909\n",
      "Epoch 35/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0280 - accuracy: 0.9951\n",
      "Epoch 36/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0427 - accuracy: 0.9933\n",
      "Epoch 37/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0406 - accuracy: 0.9930\n",
      "Epoch 38/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.1003 - accuracy: 0.9850\n",
      "Epoch 39/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0465 - accuracy: 0.9916\n",
      "Epoch 40/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0231 - accuracy: 0.9949\n",
      "Epoch 41/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0351 - accuracy: 0.9931\n",
      "Epoch 42/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.1015 - accuracy: 0.9871\n",
      "Epoch 43/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0598 - accuracy: 0.9903\n",
      "Epoch 44/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0368 - accuracy: 0.9929\n",
      "Epoch 45/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0618 - accuracy: 0.9918\n",
      "Epoch 46/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0356 - accuracy: 0.9935\n",
      "Epoch 47/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0428 - accuracy: 0.9928\n",
      "Epoch 48/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0379 - accuracy: 0.9938\n",
      "Epoch 49/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.1029 - accuracy: 0.9894\n",
      "Epoch 50/50\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0523 - accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x218f1614290>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos el modelo\n",
    "modelANN.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#Ajustamos el modelo\n",
    "modelANN.fit(X_train,y_train,epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 1s 4ms/step - loss: 0.4466 - accuracy: 0.9717\n",
      "loss_ann = 0.4466108977794647,accuracy_ann = 0.971666693687439\n"
     ]
    }
   ],
   "source": [
    "#Evaluamos el modelo ANN\n",
    "loss_ann,accuracy_ann = modelANN.evaluate(X_test,y_test)\n",
    "print(f'{loss_ann = },{accuracy_ann = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = kr.models.Sequential()\n",
    "\n",
    "# Agregamos la primera capa de convolución 2D\n",
    "modelCNN.add(kr.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# Capa de max pooling\n",
    "modelCNN.add(kr.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda capa de convolución 2D\n",
    "modelCNN.add(kr.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Capa de max pooling\n",
    "modelCNN.add(kr.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Capa de aplanamiento\n",
    "modelCNN.add(kr.layers.Flatten())\n",
    "\n",
    "# Capa densa\n",
    "modelCNN.add(kr.layers.Dense(128, activation='relu'))\n",
    "# Capa de salida\n",
    "modelCNN.add(kr.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.4896 - accuracy: 0.9343\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0693 - accuracy: 0.9787\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0487 - accuracy: 0.9847\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0457 - accuracy: 0.9861\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0361 - accuracy: 0.9889\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0323 - accuracy: 0.9904\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0263 - accuracy: 0.9916\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0253 - accuracy: 0.9926\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0224 - accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0213 - accuracy: 0.9941\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0180 - accuracy: 0.9947\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0158 - accuracy: 0.9960\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0191 - accuracy: 0.9953\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0188 - accuracy: 0.9958\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0161 - accuracy: 0.9960\n",
      "Epoch 19/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0203 - accuracy: 0.9953\n",
      "Epoch 20/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 21/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0193 - accuracy: 0.9960\n",
      "Epoch 22/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0157 - accuracy: 0.9967\n",
      "Epoch 23/50\n",
      "1050/1050 [==============================] - 14s 13ms/step - loss: 0.0096 - accuracy: 0.9980\n",
      "Epoch 24/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0211 - accuracy: 0.9965\n",
      "Epoch 25/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0111 - accuracy: 0.9977\n",
      "Epoch 26/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0103 - accuracy: 0.9977\n",
      "Epoch 27/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0166 - accuracy: 0.9966\n",
      "Epoch 28/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0114 - accuracy: 0.9977\n",
      "Epoch 29/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0188 - accuracy: 0.9969\n",
      "Epoch 30/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0117 - accuracy: 0.9978\n",
      "Epoch 31/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0173 - accuracy: 0.9971\n",
      "Epoch 32/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0191 - accuracy: 0.9970\n",
      "Epoch 33/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0117 - accuracy: 0.9979\n",
      "Epoch 34/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0147 - accuracy: 0.9979\n",
      "Epoch 35/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0143 - accuracy: 0.9975\n",
      "Epoch 36/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0156 - accuracy: 0.9980\n",
      "Epoch 37/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0254 - accuracy: 0.9971\n",
      "Epoch 38/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0119 - accuracy: 0.9984\n",
      "Epoch 39/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0214 - accuracy: 0.9974\n",
      "Epoch 40/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0130 - accuracy: 0.9981\n",
      "Epoch 41/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0134 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0124 - accuracy: 0.9985\n",
      "Epoch 43/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0123 - accuracy: 0.9984\n",
      "Epoch 44/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0104 - accuracy: 0.9985\n",
      "Epoch 45/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0172 - accuracy: 0.9985\n",
      "Epoch 46/50\n",
      "1050/1050 [==============================] - 14s 14ms/step - loss: 0.0110 - accuracy: 0.9988\n",
      "Epoch 47/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0235 - accuracy: 0.9978\n",
      "Epoch 48/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0151 - accuracy: 0.9987\n",
      "Epoch 49/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0259 - accuracy: 0.9976\n",
      "Epoch 50/50\n",
      "1050/1050 [==============================] - 15s 14ms/step - loss: 0.0087 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x218f1ba0f10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos el modelo\n",
    "modelCNN.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#Ajustamos el modelo\n",
    "modelCNN.fit(X_train,y_train,epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 2s 8ms/step - loss: 0.3702 - accuracy: 0.9854\n",
      "loss_cnn = 0.3702203929424286,accuracy_cnn = 0.9853571653366089\n"
     ]
    }
   ],
   "source": [
    "#Evaluamos el modelo CNN\n",
    "loss_cnn,accuracy_cnn = modelCNN.evaluate(X_test,y_test)\n",
    "print(f'{loss_cnn = },{accuracy_cnn = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.446611</td>\n",
       "      <td>0.971667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.370220</td>\n",
       "      <td>0.985357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo      Loss  Accuracy\n",
       "0    ANN  0.446611  0.971667\n",
       "1    CNN  0.370220  0.985357"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos la tabla para comparar los valores de loss y accuracy de ambos modelos\n",
    "data = {'Modelo': ['ANN', 'CNN'],\n",
    "        'Loss': [loss_ann, loss_cnn],\n",
    "        'Accuracy': [accuracy_ann, accuracy_cnn]}\n",
    "\n",
    "tabla = pd.DataFrame(data)\n",
    "tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Neuronal Artificial (ANN)  \n",
    "Para crear este modelo se trabajó con una capa densa, 3 capas ocultas y una capa de salida. Al principio se habían escogido 5 capas ocultas por la cantidad de datos de entrada que esta recibiria, pero consumía mucho recurso computacional, se redujo a 3 capas y disminuyó el loss y aumentó el accuracy. Creyendo que al reducir capas mejorarían estos valores se probó con una y dos capas pero los resultados fueron insatisfactorios, por lo que dejamos 3 capas.  \n",
    "\n",
    "Red Neuronal Convolucional (CNN)  \n",
    "Se trabajó con 2 capas de convolucion con el shape que tienen las imagenes de 28x28 y una capa max pooling para cada capa de convolución, esto con el objetivo de reducir la probabilidad de sobreajuste. Se agregó una capa densa antes de la capa de salida para aprender patrones sobre las caracteristicas extraidas por las capas de convolución y la capa de salida con una función de activación softmax.  \n",
    "\n",
    "Para ambos modelos se trabajó con el mismo reshape y split del dataset, con un 80% de datos para entrenamiento y un 20% para testeo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONES  \n",
    "Para los problemas de visión por computadora, o al menos este problema en especifico, la mejor técnica para crear algoritmos de clasificación es utilizar una Red Neuronal Convolucional (CNN), aunque el accuracy fue muy parecido, el parámetro loss si tuvo gran impacto.  \n",
    "\n",
    "Esto concuerda con la teoria de que las CNN son las mejores para trabajar con imagenes, videos o datos de visión por computadora, ya que están hechas especialmente para este fin y están optimizadas para trabajar con mayor cantidad de parámetros y datos en comparación con las ANN. Esto fue comprobado ya que el modelo ANN tardó en compilar mucho mas tiempo que el CNN.  \n",
    "\n",
    "Cabe mencionar que se podrían probar muchas mas configuraciones en la arquitectura del modelo ANN para mejorar su rendimiento, pero de igual manera podría hacerse con el CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reciente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
